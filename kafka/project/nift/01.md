# 01-데이터 정합성 따지기

#### 기존 프로젝트

Spring Boot + MySQL 조합을 사용.\
프론트엔드에서 블록체인과 상호작용한 후 트랜잭션을 발생시키면,\
DB에 저장하는 방식은 정합성, 신뢰도 문제로 인해 일정 주기로 `@Scheduled`를 통해 정합성 유지 작업을 진행.

***

#### 문제점 (단점)

1. 이벤트 수집을 **polling**에 의존
2. 확장성 떨어짐
   * 추후, 멀티 인스턴스로 확장되면 중복 데이터 저장 가능성 올라감.
3. 블록 생성 주기에 따라 polling 타이밍과 반영 타이밍이 **불일치**할 수 있음

***

#### 고민 1. 이벤트를 어떻게 감지할까?

웹소켓을 이용한 **blockchain → frontend로의 직접 통신**은 불안정하고, 권장되지 않음.

→ **Node.js에서 Web3를 활용한 HTTP 기반 Polling 방식으로 블록체인 이벤트를 감지한다.**

***

#### 고민 2. WebFlux를 활용할 수 있을까?

* 치명적인 문제점
  * Web3.js는 Blocking 작업이다.
  * 이렇게 되면, WebFlux를 사용하는 의미가 없어짐.
  * 그럼 아래와 같은 구조로는 괜찮지 않을까?
* 구조

> frontend → blockchain → node.js listener -> 이벤트 감지 -> WebFlux Rest 호출 -> db 저장

* 또 다른 문제점
  * 이러면, 트래픽이 몰릴 때, 이벤트 감지 후 webflux 호출 부분에서 문제 생기지 않을까?
  * 그리고, 이 구조에서 webflux의 의미가 있는가? spring-boot로 충분하지 않을까?

결론: WebFlux를 도입하는데에 있어 운영상 얻을 수 있는 장점이 없다. (나중에 배민 같이 사용하는 사람 짱 많아지면 이점이 생기겠지...)

***

#### 고민 3. Kafka의 pub/sub 구조는 쓸만한가?

* 구조

> frontend → blockchain → node.js listener -> 이벤트 감지 시 kafka publish -> Kafka consumer → MySQL 저장

* 장점
  1. 높은 트래픽에도 안정성 보장
  2. Polling 타이밍과 무관하게 데이터 흐름 관리 가능
  3. 재처리(Replay) 및 실패 대응 구조 설계 가능
  4. 다양한 기능(알림, 로그 기록 등)으로 손쉽게 확장 가능

***

#### 나중에 더 공부해야할 포인트

1. kafka 토픽 관리
   * 지금은 그냥 tx-log로 모두 한꺼번에 하고 있지만, event 토픽 별로 나눠서 하는 걸로 변경 가능
2. kafka 병렬 처리
   * 파티션, 레플리케이션
